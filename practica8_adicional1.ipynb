{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practica8_adicional1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzazenbi/MyApplication/blob/master/practica8_adicional1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cqwiB9hHrvfz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Práctica 8. Ejercicio adicional 1: Preprocesado de datos\n",
        "\n",
        "La calidad de los datos y la cantidad de información relevante que dichos datos contienen son factores clave a la hora de que un algoritmo de aprendizaje sea capaz de aprender. En este notebook se ven distintas técnicas de preprocesado de datos y su impacto a la hora de entrenar modelos. "
      ]
    },
    {
      "metadata": {
        "id": "tdEG31Qzrvf5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 0. Carga de librerías y del dataset \n",
        "\n",
        "Para este notebook vamos a utilizar el dataset del Vino, otro dataset open-source que está disponible en el [repositorio UCI](https://archive.ics.uci.edu/ml/datasets/wine). Este dataset consiste en 178 muestras de vinos y 13 descriptores de distintas propiedades químicas. \n",
        "\n",
        "Usando pandas vamos a descargar directamente dicho dataset. También definimos en la siguiente celda el nombre de las columnas."
      ]
    },
    {
      "metadata": {
        "id": "bhSayA3_rvgE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7N6YSOpcrvgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
        "                     header=None)\n",
        "df_wine.columns = ['Class label', 'Alcohol', 'Malid acid', 'Ash', 'Alcalinity of ash', \n",
        "                  'Magnesium', 'Total phenols','Flavanoids','Nonflavanoid phenols', \n",
        "                  'Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines',\n",
        "                  'Proline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0hIcIfzxrvgm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación podemos ver las categorías de vinos de nuestro dataset."
      ]
    },
    {
      "metadata": {
        "id": "0i_rFZwervgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Class labels',np.unique(df_wine['Class label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVd_Pkc_rvg3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Pregunta\n",
        "¿Cuántas clases hay?"
      ]
    },
    {
      "metadata": {
        "id": "aiFOWWpsrvg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dw2oQ8ShrvhO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La siguiente instrucción muestra las primeras filas del dataset."
      ]
    },
    {
      "metadata": {
        "id": "0lOlHoJPrvhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_wine.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxD623SFrvhg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Ejercicio\n",
        "La variable `df_wine` contiene tanto las etiquetas como los descriptores, separa dicha variable en las variables `X` e `y` como hemos hecho en otras ocasiones. Date cuenta que en este caso la etiqueta no la proporciona la última columna sino la primera, y que los descriptores van desde la columna 1 hasta la última. "
      ]
    },
    {
      "metadata": {
        "id": "aUq0xHsFrvhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df_wine.values[:,1:]\n",
        "y = df_wine.values[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AT5ogyeFrvh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La siguiente celda debería producir los siguientes resultados:\n",
        "\n",
        "| Expresión | Resultado |\n",
        "|---|---|\n",
        "| X[0] | [  1.42300000e+01,1.71000000e+00,2.43000000e+00,1.56000000e+01,1.27000000e+02,2.80000000e+00   3.06000000e+00,2.80000000e-01,2.29000000e+00,5.64000000e+00, 1.04000000e+00,3.92000000e+00,1.06500000e+03] |\n",
        "| y[5] | 1.0 |"
      ]
    },
    {
      "metadata": {
        "id": "d-JRhLOervh7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(X[0])\n",
        "print(y[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjbu12qbrviB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Ejercicio\n",
        "Como hacemos de manera habitual vamos a partir el dataset en los conjuntos de entrenamiento y test. Utiliza el 30% para el conjunto de entrenamiento y usa como `random_state` el valor 0."
      ]
    },
    {
      "metadata": {
        "id": "IcA_AX7srviC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = ????"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wjd5RzzCrviG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Escalando los descriptores\n",
        "\n",
        "El escalado de los descriptores es un paso habitual de preprocesamiento. La mayoría de algoritmos de aprendizaje aprenden mucho mejor cuando los descriptores están en la misma escala. \n",
        "\n",
        "La importancia de escalar los descriptores se puede ilustrar con el siguiente ejemplo. Suponed que tenemos dos descriptores donde un descriptor se mide en una escala de 1 a 10 y otra se mide en una escala 1 a 100000. Cuando pensamos en el error cuadrático, es intuitivo que los algoritmos de optimización ajustarán los pesos de acuerdo a los errores producidos en el segundo descriptor. Otro ejemplo sería en el algoritmo KNN con la medida Euclídea, donde el cálculo de las distancias va a estar dominado por el segundo descriptor.\n",
        "\n",
        "Existen dos aproximaciones distintas para escalar los descriptores: la normalización y la estandarización.\n",
        "\n",
        "### 1.1. Normalización\n",
        "\n",
        "La normalización se refiere al proceso de reescalar los descriptores en el rango $[0,1]$. Para llevar a cabo este reescalado se puede aplicar el escalado min-max a cada columna de un descriptor. En concreto para calcular este valor usamos la siguiente fórmula:\n",
        "$$x_{norm}^{(i)} = \\frac{x^{(i)}-x_{min}}{x_{max}-x_{min}}$$\n",
        "donde $x_{norm}^{(i)}$ es el nuevo valor de la instancia $i$ del dataset para un descriptor, $x^{(i)}$ es el valor original de la instancia para ese descriptor, $x_{min}$ es el menor valor que toma ese descriptor para todas las instancias del dataset, y $x_{max}$ es el mayor valor que toma ese descriptor para todas las instancias del dataset.\n",
        "\n",
        "Este procedimiento está implementado en sklearn y puede usarse del siguiente modo. Importamos la librería y definimos un objeto de la clase `MinMaxScaler`."
      ]
    },
    {
      "metadata": {
        "id": "L_6Lq0PCrviH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJVDE87CrviN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Llevamos a cabo el reescalado tanto del conjunto de entrenamiento utilizando la función `fit_transform` del objeto `mms`, y luego reescalamos el conjunto de test utilizando la función `transform`. Esto se hace para que el reescalado del conjunto de test utilice los mismos valores de reescalado que el conjunto de entrenamiento."
      ]
    },
    {
      "metadata": {
        "id": "eF15P-4mrviO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fT0ytFQXrviW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2. Estandarización\n",
        "\n",
        "La normalización es una técnica útil cuando necesitamos que los nuevos valores de los descriptores estén en un intervalo, la estandarización puede ser más útil para los algoritmos de aprendizaje. La razón es que muchos algoritmos como la regresión logística, SVMs o las redes neuronales inicializan los pesos a 0 o a valores aleatoreos cercanos a 0. Usando la estandarización se consiguen centrar las columnas de descriptores con media 0 y desviación típica 1 de modo que las columnas de descriptores toman la forma de una distribución normal lo que hace que se aprendan de manera más sencilla los pesos. \n",
        "\n",
        "El proceso de estandarización viene dado por la siguiente fórmula:\n",
        "$$x^{(i)}_{std} = \\frac{x^{(i)}-\\mu_x}{\\sigma_x}$$\n",
        "donde $\\mu_x$ es la media de la muestra para cada columna de descriptores, $\\sigma_x$ es la desviación típica, y $x^{(i)}_{std}$ es el valor calculado a partir del original $x^{(i)}$.\n",
        "\n",
        "La siguiente tabla muestra la diferencia entre los valores normalizados y estandarizados en un dataset que contiene los números del 0 al 5. \n",
        "\n",
        "| Entrada | Estandarizado | Normalizado |\n",
        "| --- | --- | --- |\n",
        "| 0.0 | -1.33 | 0.0 |\n",
        "| 1.0 | -0.8 | 0.2 |\n",
        "| 2.0 | -0.26 | 0.4 |\n",
        "| 3.0 | 0.26 | 0.6 |\n",
        "| 4.0 | 0.8 | 0.8 |\n",
        "| 5.0 | 1.33 | 1.0 |\n",
        "\n",
        "Al igual que para la normalización, sklearn también implementa la estandarización y se utiliza del mismo modo."
      ]
    },
    {
      "metadata": {
        "id": "VtnKxkr4rviX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "stdsc = StandardScaler()\n",
        "X_train_std = stdsc.fit_transform(X_train)\n",
        "X_test_std = stdsc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnbsnqWArvig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Seleccionando descriptores relevantes\n",
        "\n",
        "Cuando un modelo funciona mucho mejor en el conjunto de entrenamiento que en el de test, estos es un claro caso de _sobreajuste_. Es decir, que el modelo ha ajustado sus parámetros para funcionar bien en el conjunto de entrenamiento pero no generaliza bien a datos reales. Existen distintas técnicas para reducir el sobreajuste, la más sencilla pero también más complicada de llevar a cabo consiste en conseguir más datos para entrenar el modelo; esto en muchas ocasiones no es posible. En este apartado vamos a ver otra técnica que consiste en reducir el sobreajuste que consiste en utilizar la reducción de dimensionalidad. \n",
        "\n",
        "Ya vimos que existen dos tipos de técnicas para reducir la dimensionalidad: la selección de descriptores y la extracción de descriptores. En este apartado nos vamos a centrar en el uso del método de selección secuencial hacia atrás. Este algoritmo no está implementado por defecto en sklearn, pero lo tienes disponible en el fichero sbs.py. Vamos a ver como funciona nuestro selector de descriptores utilizando el clasificador KNN. Comentamos cargando las librerías necesarias. "
      ]
    },
    {
      "metadata": {
        "id": "OJB883dQrvil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sbs import SBS\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUZpif9Frvio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construimos el clasificador."
      ]
    },
    {
      "metadata": {
        "id": "NsTI5qwjrvip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yZxhaiorvit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construimos nuestro selector de descriptores y le indicamos que al menos tiene que tomar 1 descriptor. El proceso consiste en construir una instancia de la clase `SBS` donde le indicamos el clasificador y el mínimo número de descriptores, y luego entrenarla."
      ]
    },
    {
      "metadata": {
        "id": "xTRNaQzLrvit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sbs= SBS(knn,k_features=1)\n",
        "sbs.fit(X_train_std,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wrehij9Yrvix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El objeto de la clase sbs almacena las puntuaciones de los mejores subconjuntos de descriptores en cada paso utilizando una parte del conjunto de test como conjunto de validación, así que podemos mostrar la precisión del clasificador para los distintos subconjuntos."
      ]
    },
    {
      "metadata": {
        "id": "drCUxXfgrvix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k_feat = [len(k) for k in sbs.subsets_]\n",
        "plt.plot(k_feat,sbs.scores_,marker='o')\n",
        "plt.ylim([0.7,1.1])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Numero descriptores')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q4o0swT-rvi3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como se puede ver en la figura anterior la accuracy del algoritmo KNN aumenta al reducir el número de descriptores lo cual se debe a la maldición de la dimensionalidad. Como se puede ver en la gráfica, el algoritmo KNN alcanza una accuracy del 100% utilizando entre 5 y 11 descriptores. \n",
        "\n",
        "Podemos tomar los 5 descriptores más relevantes y ver cuáles son. Como estamos utilizando la eliminación hacia atrás para acceder a los 5 descriptores más relevantes tenemos que acceder al campo `subsets_` (que es una lista) e indicalre el índice que sería 13 (número total de descriptores) - 5 (número de descriptores con los que nos quedamos)."
      ]
    },
    {
      "metadata": {
        "id": "CBzqHlXErvi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k5 = list(sbs.subsets_[8]) \n",
        "print(df_wine.columns[1:][k5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9ugjzQCrvi-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos ahora a evaluar el rendimiento del clasificador KNN en el conjunto de test. Primero lo consideramos sin estandarizar. "
      ]
    },
    {
      "metadata": {
        "id": "bJ4F9CSJrvi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn.fit(X_train,y_train)\n",
        "print('Training accuracy:', knn.score(X_train,y_train))\n",
        "print('Test accuracy:', knn.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Agqe4gK8rvjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación utilizando el dataset normalizado."
      ]
    },
    {
      "metadata": {
        "id": "kqm5wdprrvjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn.fit(X_train_norm,y_train)\n",
        "print('Training accuracy:', knn.score(X_train_norm,y_train))\n",
        "print('Test accuracy:', knn.score(X_test_norm,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r8CELagurvjK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación utilizando el dataset estandarizado."
      ]
    },
    {
      "metadata": {
        "id": "Sy7HMj1XrvjL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn.fit(X_train_std,y_train)\n",
        "print('Training accuracy:', knn.score(X_train_std,y_train))\n",
        "print('Test accuracy:', knn.score(X_test_std,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_i6I775rvjQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Por último considerando solo los 5 descriptores más relevantes. "
      ]
    },
    {
      "metadata": {
        "id": "tMPuVHXsrvjR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn.fit(X_train_std[:,k5],y_train)\n",
        "print('Training accuracy:', knn.score(X_train_std[:,k5],y_train))\n",
        "print('Test accuracy:', knn.score(X_test_std[:,k5],y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oeuNLyzGrvjU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Pregunta\n",
        "¿Qué ha ocurrido al estandarizar los datos? ¿y al normalizarlos? ¿Ha mejorado la accuracy de nuestro clasificador? ¿Qué ha ocurrido al utilizar los 5 descriptores más importantes?"
      ]
    },
    {
      "metadata": {
        "id": "IKP8nJmfrvjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cIrGiBprvje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Viendo la importancia de los descriptores \n",
        "\n",
        "Una técnica que también resulta útil para seleccionar descriptores relevantes a partir de un dataset consiste en utilizar [_random forests_](http://scikit-learn.org/stable/modules/ensemble.html#forest) un método en el cual se entrenan varios árboles de decisión y se organiza una votación entre esos modelos para decidir la predicción.\n",
        "\n",
        "Utilizando los random forest podemos ver la importancia de cada descriptor usando el atributo `feature_importances_` que está accesible después de entrenar uno de estos clasificadores. Ejecutando el siguiente código se entrenará uno de estos modelos utilizando 1000 árboles de decisión y se obtendrá un ranking de los 13 descriptores. \n",
        "\n",
        "Comenzamos cargando las libreráis necesarias."
      ]
    },
    {
      "metadata": {
        "id": "YuBI_Lcdrvjh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcU8XuzGrvjm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Obtenemos el nombre de cada descriptor."
      ]
    },
    {
      "metadata": {
        "id": "7d1vUAcBrvjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "etiquetas_descriptores = df_wine.columns[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CuJkD1Ytrvjs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construimos el _random forest_."
      ]
    },
    {
      "metadata": {
        "id": "10uVPk1qrvjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "forest = RandomForestClassifier(n_estimators=1000,random_state=0,n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1OX_jZ0rvjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo. Notar que usamos directamente el dataset sin estandarizar, esto es debido a que los árboles de decisión no están afectados por la escala de los atributos. "
      ]
    },
    {
      "metadata": {
        "id": "yZA4Oj4arvjx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "forest.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38Y_gFvprvj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Obtenemos la relevancia de cada descriptor y los índices para ordenar de mayor a menor dichas relevancias."
      ]
    },
    {
      "metadata": {
        "id": "FfJw38Uervj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "relevancias = forest.feature_importances_\n",
        "indices = np.argsort(relevancias)[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLsisme7rvj8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Por último mostramos la importancia de cada descriptor."
      ]
    },
    {
      "metadata": {
        "id": "yY-8IXmHrvj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for f in range(X_train.shape[1]):\n",
        "    print(\"%2d) %-*s %f\" % (f+1,30,etiquetas_descriptores[indices[f]],relevancias[indices[f]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCxOyQ0qrvkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Pregunta\n",
        "¿Cuál es el descriptor más relevante?"
      ]
    },
    {
      "metadata": {
        "id": "8Wq7MqmSrvkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XvoPgpecrvkQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos a mostrar un gráfico con la relevancia de cada descriptor. "
      ]
    },
    {
      "metadata": {
        "id": "XmlJnh2zrvkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.title('Relevancia de los descriptores')\n",
        "plt.bar(range(X_train.shape[1]),relevancias[indices],color='lightblue',align='center')\n",
        "plt.xticks(range(X_train.shape[1]),etiquetas_descriptores[indices],rotation=90)\n",
        "plt.xlim([-1,X_train.shape[1]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}